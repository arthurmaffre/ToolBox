# Device Module â€” README

## ğŸ“Œ Overview
This module provides a **clean, professional, and frictionless way** to select the best available device for your PyTorch projects. It detects and prioritizes CUDA, MPS (Apple Silicon), or CPU depending on your environment.

## âš™ï¸ Features
- **Automatic device detection** with multiple strategies.
- **Flexible selection modes**:
  - `auto`: CUDA > MPS > CPU
  - `cuda`: CUDA > CPU
  - `cpu`: CPU only (forces CPU usage)
- **Plug-and-play**: Easily integrate into any PyTorch project.

## ğŸš€ Installation
Place `device.py` in your **ToolBox** repository under the appropriate module folder.

## ğŸ› ï¸ Usage
```python
from device import get_device

device = get_device("auto")  # Options: "auto", "cuda", "cpu"
print(f"Using device: {device}")
```

### ğŸ”„ Modes Explained
- **`auto`** â†’ Uses CUDA if available, else MPS (Mac), else CPU.
- **`cuda`** â†’ Uses CUDA if available, otherwise falls back to CPU.
- **`cpu`** â†’ Forces CPU regardless of hardware.

## âœ… Best Practices
- Call `get_device()` **once** at the start of your script.
- Pass the returned `device` to your models and tensors using `.to(device)`.
- Combine with your training loop for seamless execution.

## ğŸ“‚ Example Integration
```python
model = MyModel().to(device)
inputs = inputs.to(device)
outputs = model(inputs)
```

## ğŸ§  Why this module?
This small utility is part of your **ToolBox** to:
- **Avoid repeating boilerplate code**.
- **Simplify device handling across projects**.
- **Ensure maximum performance** by using the best hardware available automatically.